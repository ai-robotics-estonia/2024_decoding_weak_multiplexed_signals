{"_timestamp":1.7314334352797725e+09,"gradients/feature_extractor.5.bias":{"_type":"histogram","values":[128],"bins":[0,0]},"gradients/feature_extractor.1.bias":{"values":[64],"bins":[0,0],"_type":"histogram"},"gradients/feature_extractor.9.weight":{"_type":"histogram","values":[256],"bins":[0,0]},"gradients/feature_extractor.0.bias":{"values":[64],"bins":[0,0],"_type":"histogram"},"_wandb":{"runtime":202},"gradients/feature_extractor.5.weight":{"bins":[0,0],"_type":"histogram","values":[128]},"gradients/fc.1.weight":{"_type":"histogram","values":[293632],"bins":[0,0]},"gradients/feature_extractor.0.weight":{"_type":"histogram","values":[2304],"bins":[0,0]},"Average Validation Loss":41.6382252559727,"gradients/additional_conv_layers.4.weight":{"values":[128],"bins":[0,0],"_type":"histogram"},"gradients/feature_extractor.4.weight":{"_type":"histogram","values":[73728],"bins":[0,0]},"_runtime":202.230699173,"gradients/additional_conv_layers.1.weight":{"bins":[0,0],"_type":"histogram","values":[256]},"gradients/additional_conv_layers.0.weight":{"bins":[0,0],"_type":"histogram","values":[1.179648e+06]},"gradients/feature_extractor.8.weight":{"_type":"histogram","values":[294912],"bins":[0,0]},"gradients/additional_conv_layers.1.bias":{"values":[256],"bins":[0,0],"_type":"histogram"},"gradients/feature_extractor.1.weight":{"values":[64],"bins":[0,0],"_type":"histogram"},"Train Loss":100,"gradients/feature_extractor.9.bias":{"bins":[0,0],"_type":"histogram","values":[256]},"gradients/additional_conv_layers.3.bias":{"values":[128],"bins":[0,0],"_type":"histogram"},"gradients/fc.1.bias":{"_type":"histogram","values":[1],"bins":[0,0]},"gradients/additional_conv_layers.0.bias":{"_type":"histogram","values":[256],"bins":[0,0]},"gradients/feature_extractor.4.bias":{"_type":"histogram","values":[128],"bins":[0,0]},"gradients/additional_conv_layers.3.weight":{"values":[294912],"bins":[0,0],"_type":"histogram"},"gradients/additional_conv_layers.4.bias":{"bins":[0,0],"_type":"histogram","values":[128]},"gradients/feature_extractor.8.bias":{"values":[256],"bins":[0,0],"_type":"histogram"},"_step":1196,"Average Train Loss":38.42929490996059}